{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OYELdWJBsBb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgzTgkaL9OnI"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fvo8VpnvRcDM",
        "outputId": "76e0951a-6f51-448b-9b4d-27f4ec19607a"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**포지셔널 인코딩**"
      ],
      "metadata": {
        "id": "btCZWBm7Me7h"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY6lwO-oWZJd"
      },
      "source": [
        "# 최종 버전\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :], # 0 ~ d_model\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    angle_rads = np.zeros(angle_rads.shape)\n",
        "    angle_rads[:, 0::2] = sines\n",
        "    angle_rads[:, 1::2] = cosines\n",
        "    \n",
        "    pos_encoding = tf.constant(angle_rads)\n",
        "    print(pos_encoding.shape)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    print(pos_encoding.shape)\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_pos_encoding = PositionalEncoding(50, 128)\n",
        "sample_pos_encoding.pos_encoding.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj57jtbNlmCj",
        "outputId": "c6afa31e-6e1d-401a-d78a-00e915016719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 128)\n",
            "(1, 50, 128)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
              "          1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "        [ 8.41471016e-01,  5.40302277e-01,  7.61720419e-01, ...,\n",
              "          1.00000000e+00,  1.15478222e-04,  1.00000000e+00],\n",
              "        [ 9.09297466e-01, -4.16146815e-01,  9.87046242e-01, ...,\n",
              "          9.99999940e-01,  2.30956444e-04,  1.00000000e+00],\n",
              "        ...,\n",
              "        [ 1.23573124e-01, -9.92335498e-01,  1.39922664e-01, ...,\n",
              "          9.99980330e-01,  5.42744994e-03,  9.99985278e-01],\n",
              "        [-7.68254697e-01, -6.40144348e-01, -6.63569212e-01, ...,\n",
              "          9.99979496e-01,  5.54292602e-03,  9.99984622e-01],\n",
              "        [-9.53752637e-01,  3.00592542e-01, -9.99784708e-01, ...,\n",
              "          9.99978662e-01,  5.65840257e-03,  9.99983966e-01]]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaled Dot-Production Attention**"
      ],
      "metadata": {
        "id": "JfFxvDMTNTsX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6534luH9d0K"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
        "\n",
        "  # Q와 K의 곱. 어텐션 스코어 행렬.\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 스케일링\n",
        "  # dk의 루트값으로 나눠준다.\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
        "  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
        "  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MultiHeadAttention**"
      ],
      "metadata": {
        "id": "NJxPLZA6NXro"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNU5ilcw9f3q"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    # d_model을 num_heads로 나눈 값.\n",
        "    # 논문 기준 : 64\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    # WQ, WK, WV에 해당하는 밀집층 정의\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    # WO에 해당하는 밀집층 정의\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    \n",
        "    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
        "    # q : (batch_size, query의 문장 길이, d_model)\n",
        "    # k : (batch_size, key의 문장 길이, d_model)\n",
        "    # v : (batch_size, value의 문장 길이, d_model)\n",
        "    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 2. 헤드 나누기\n",
        "    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
        "    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 4. 헤드 연결(concatenate)하기\n",
        "    # (batch_size, query의 문장 길이, d_model)\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 5. WO에 해당하는 밀집층 지나기\n",
        "    # (batch_size, query의 문장 길이, d_model)\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrCdqp8z9ily"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, key의 문장 길이)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**인코더**"
      ],
      "metadata": {
        "id": "S8pN5niKPVzl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nskamzrs9j1K"
      },
      "source": [
        "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 인코더는 패딩 마스크 사용 -> 어텐션에서 패딩 토큰 제외\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "          'mask': padding_mask # 패딩 마스크 사용\n",
        "      })\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제로 트랜스포머는 num_layers 개수만큼의 인코더 층을 사용하므로 이를 여러번 쌓는 코드를 별도 구현합니다. "
      ],
      "metadata": {
        "id": "f_DCRCZUPyJh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34a0WK-B9lgi"
      },
      "source": [
        "def encoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 인코더는 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 포지셔널 인코딩 + 드롭아웃\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # 인코더를 num_layers개 쌓기\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**디코더**"
      ],
      "metadata": {
        "id": "0DAbVD1EQt3K"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng1ysGoJ9mha"
      },
      "source": [
        "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0) #  Lower triangular part.\n",
        "  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LS-ah1uRlir",
        "outputId": "774382e5-690c-4886-dc7f-42f6bef80ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3QDoLz49oPK"
      },
      "source": [
        "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "\n",
        "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
        "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
        "      })\n",
        "\n",
        "  # 잔차 연결과 층 정규화\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
        "          'mask': padding_mask # 패딩 마스크\n",
        "      })\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "포지셔널 인코딩 후 디코더 층을 num_layers의 개수만큼 쌓는 코드입니다."
      ],
      "metadata": {
        "id": "IVTU23pKSUxd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i9lZmji9qDa"
      },
      "source": [
        "def decoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 포지셔널 인코딩 + 드롭아웃\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # 디코더를 num_layers개 쌓기\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**트랜스포머 구현하기**"
      ],
      "metadata": {
        "id": "xwOPBIfASXZP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GEC6CXF9q7S"
      },
      "source": [
        "def transformer(vocab_size, num_layers, dff,\n",
        "                d_model, num_heads, dropout,\n",
        "                name=\"transformer\"):\n",
        "\n",
        "  # 인코더의 입력\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 디코더의 입력\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더의 패딩 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 디코더의 패딩 마스크(두번째 서브층)\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "##################################################################\n",
        "\n",
        "  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
        "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
        "\n",
        "  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
        "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 다음 단어 예측을 위한 출력층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = 1\n",
        "tf.cast(tf.not_equal(y_true, 0), tf.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW3kgkW5T4BZ",
        "outputId": "71620e6a-7ecd-4489-b411-3c4604d64029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DgCW2_k-8KM"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32) # y_true가 0(패딩이면) -> 0 , 1이면 -> 1\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss) #Computes the mean of elements across dimensions of a tensor."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkkz7qka_tSU"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9tpZXei_1xK"
      },
      "source": [
        "# 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5W2D7Uq_u_x"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "t7ku6KRb_545",
        "outputId": "3d5f65be-1317-4901-db8f-ab6f72308f40"
      },
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/trans_koreng_project/songs/전처리_노래제목&가사(벅스).csv')\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0           title  \\\n",
              "0           0  천만분의 1의 확률의 너    \n",
              "1           1          술이 뭐길래   \n",
              "2           2    그때 그 순간 그대로    \n",
              "3           3          나의 X에게   \n",
              "4           4        일과 이분의 일   \n",
              "\n",
              "                                               lylic  \n",
              "0   Every seconds Every minutes 너를 만나기 위해 모든 시간들을...  \n",
              "1   오늘도 이렇게 어제처럼 잔을 꺼내 나 혼자서 따른 잔에 내 입술을 기대 눈물 반 ...  \n",
              "2   잘 지냈지 조금은 어색해 요즘 좋아 보여 인사 나누며 사실 궁금한 게 너무 많았는...  \n",
              "3   우리 다시 만날래 예쁘게 빛나던 모든 추억들이 너무 그리워 너의 품에 안길래 이 ...  \n",
              "4   멀리서 널 보았을 때 다른 길로 갈까 생각했는데 변한 듯한 널 보고 싶고 짧은 인...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c226788-e7c8-4be3-9dc2-3e5009aa414e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>lylic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>천만분의 1의 확률의 너</td>\n",
              "      <td>Every seconds Every minutes 너를 만나기 위해 모든 시간들을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>술이 뭐길래</td>\n",
              "      <td>오늘도 이렇게 어제처럼 잔을 꺼내 나 혼자서 따른 잔에 내 입술을 기대 눈물 반 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>그때 그 순간 그대로</td>\n",
              "      <td>잘 지냈지 조금은 어색해 요즘 좋아 보여 인사 나누며 사실 궁금한 게 너무 많았는...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>나의 X에게</td>\n",
              "      <td>우리 다시 만날래 예쁘게 빛나던 모든 추억들이 너무 그리워 너의 품에 안길래 이 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>일과 이분의 일</td>\n",
              "      <td>멀리서 널 보았을 때 다른 길로 갈까 생각했는데 변한 듯한 널 보고 싶고 짧은 인...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c226788-e7c8-4be3-9dc2-3e5009aa414e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c226788-e7c8-4be3-9dc2-3e5009aa414e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c226788-e7c8-4be3-9dc2-3e5009aa414e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "W9AZ0JI20Y9q",
        "outputId": "d854b41d-e3ea-49d5-d704-345c98e7ab80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0           title  \\\n",
              "0               0  천만분의 1의 확률의 너    \n",
              "1               1          술이 뭐길래   \n",
              "2               2    그때 그 순간 그대로    \n",
              "3               3          나의 X에게   \n",
              "4               4        일과 이분의 일   \n",
              "...           ...             ...   \n",
              "41881       41881           뚜벅뚜벅    \n",
              "41882       41882        해피 크리스마스   \n",
              "41883       41883     Stegosaurus   \n",
              "41884       41884    붕붕붕 스쿨버스 안전송   \n",
              "41885       41885    쓱싹쓱싹 클리니 청소송   \n",
              "\n",
              "                                                   lylic  \n",
              "0       Every seconds Every minutes 너를 만나기 위해 모든 시간들을...  \n",
              "1       오늘도 이렇게 어제처럼 잔을 꺼내 나 혼자서 따른 잔에 내 입술을 기대 눈물 반 ...  \n",
              "2       잘 지냈지 조금은 어색해 요즘 좋아 보여 인사 나누며 사실 궁금한 게 너무 많았는...  \n",
              "3       우리 다시 만날래 예쁘게 빛나던 모든 추억들이 너무 그리워 너의 품에 안길래 이 ...  \n",
              "4       멀리서 널 보았을 때 다른 길로 갈까 생각했는데 변한 듯한 널 보고 싶고 짧은 인...  \n",
              "...                                                  ...  \n",
              "41881   오늘도 뚜벅뚜벅 발길은 너무나 막연해 우리 이렇게 멀리 왔어도 느린 걸음으로 따라...  \n",
              "41882   혼자 있는 이 세상 빛이 없다 믿나요 기댈 곳 없어 두 뺨 위에 눈물만 힘든 발걸...  \n",
              "41883   One two three four five It’s a pentagon One t...  \n",
              "41884   헤헷 오늘도 안전하게 출발 스쿨비가 달려요 붕붕붕 붕붕붕 스쿨비가 달려요 붕붕 붕...  \n",
              "41885   클리니 출동 오케이 준비 오케이 오케이 준비 오케이 아침 일찍 클리니가 달려가요 ...  \n",
              "\n",
              "[41886 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93a59f82-f9e7-4876-9a6b-09f358522b9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>lylic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>천만분의 1의 확률의 너</td>\n",
              "      <td>Every seconds Every minutes 너를 만나기 위해 모든 시간들을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>술이 뭐길래</td>\n",
              "      <td>오늘도 이렇게 어제처럼 잔을 꺼내 나 혼자서 따른 잔에 내 입술을 기대 눈물 반 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>그때 그 순간 그대로</td>\n",
              "      <td>잘 지냈지 조금은 어색해 요즘 좋아 보여 인사 나누며 사실 궁금한 게 너무 많았는...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>나의 X에게</td>\n",
              "      <td>우리 다시 만날래 예쁘게 빛나던 모든 추억들이 너무 그리워 너의 품에 안길래 이 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>일과 이분의 일</td>\n",
              "      <td>멀리서 널 보았을 때 다른 길로 갈까 생각했는데 변한 듯한 널 보고 싶고 짧은 인...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41881</th>\n",
              "      <td>41881</td>\n",
              "      <td>뚜벅뚜벅</td>\n",
              "      <td>오늘도 뚜벅뚜벅 발길은 너무나 막연해 우리 이렇게 멀리 왔어도 느린 걸음으로 따라...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41882</th>\n",
              "      <td>41882</td>\n",
              "      <td>해피 크리스마스</td>\n",
              "      <td>혼자 있는 이 세상 빛이 없다 믿나요 기댈 곳 없어 두 뺨 위에 눈물만 힘든 발걸...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41883</th>\n",
              "      <td>41883</td>\n",
              "      <td>Stegosaurus</td>\n",
              "      <td>One two three four five It’s a pentagon One t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41884</th>\n",
              "      <td>41884</td>\n",
              "      <td>붕붕붕 스쿨버스 안전송</td>\n",
              "      <td>헤헷 오늘도 안전하게 출발 스쿨비가 달려요 붕붕붕 붕붕붕 스쿨비가 달려요 붕붕 붕...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41885</th>\n",
              "      <td>41885</td>\n",
              "      <td>쓱싹쓱싹 클리니 청소송</td>\n",
              "      <td>클리니 출동 오케이 준비 오케이 오케이 준비 오케이 아침 일찍 클리니가 달려가요 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41886 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93a59f82-f9e7-4876-9a6b-09f358522b9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93a59f82-f9e7-4876-9a6b-09f358522b9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93a59f82-f9e7-4876-9a6b-09f358522b9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXg6ws2s_9Ch",
        "outputId": "d38823bb-15b0-436e-ed54-880ec757a05b"
      },
      "source": [
        "print(train_data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0     0\n",
            "title         26\n",
            "lylic          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.drop_duplicates(subset=['lylic'], inplace=True)\n",
        "train_data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "kjcixeZzslOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u8IIfhXsq2M",
        "outputId": "140d803f-5d2c-4ad4-9799-a63486432549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0    0\n",
            "title         0\n",
            "lylic         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hpk8Z-P_6hh",
        "outputId": "a0d92e6a-03e5-4f45-bc33-ea1e17ac9309"
      },
      "source": [
        "print('가사 샘플의 개수 :', len(train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가사 샘플의 개수 : 25626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AKOHALL_9rJ"
      },
      "source": [
        "lyric = []\n",
        "for sentence in train_data['lylic']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    lyric.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoJs0Od8_-aB"
      },
      "source": [
        "title = []\n",
        "for sentence in train_data['title']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    title.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7Q9NFcbUKMF8",
        "outputId": "51c12e66-44d9-416c-941b-20d02a76e584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'천만분의 1의 확률의 너'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(lyric) , len(title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kDShG53K9Au",
        "outputId": "dafff2bd-6853-479b-9912-6b764aa59635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25626, 25626)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(lyric[0].split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2BLCvpZLuj8",
        "outputId": "f5a07702-e032-47f8-b5ec-9b4fce836edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "169"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cut_lyric = []\n",
        "cut_title = []\n",
        "\n",
        "for i in range(len(lyric)) :\n",
        "  token_lyric = len(lyric[i].split(' '))\n",
        "  token_title = len(title[i].split(' '))\n",
        "  if token_lyric <= 450 :\n",
        "    cut_lyric.append(lyric[i])\n",
        "    cut_title.append(title[i])\n"
      ],
      "metadata": {
        "id": "I7KyTE5OKJi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AS2olsI__KJ",
        "outputId": "3b31d044-690d-4779-cfae-71c42129e9c4"
      },
      "source": [
        "len(cut_lyric), len(cut_title)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25423, 25423)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cut_lyric[:5])\n",
        "print(cut_title[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zmitzR6MMZW",
        "outputId": "4ded2eb1-be9c-49e1-b8b2-6fb20b778f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Every seconds Every minutes 너를 만나기 위해 모든 시간들을 모래시계에 다 넣어 놓고서 우리 둘만의 이야기를 나눌 거야 기억을 건너 그 순간 그때 널 만날 수 있게 되면 아마도 기적과 같은 일이 아닐까 멈춰버린 내 시간 속에서 마침내 너를 발견한 건 천만분의 1 수많은 시행착오 그 끝에 마지막이라고 생각한 그때 우연이 아닌 운명처럼 모든 게 딱 맞아떨어진 그때 흐려진 시야 속 짙게 밴 네 향이 이끌어 너에게 자석처럼 당겨 세게 그곳에 더 닿을게 붉게 물들어 이곳엔 언제나 그랬듯 내겐 아프더라도 난 괜찮아 오직 너니까 우리 둘만의 이야기를 나눌 거야 기억을 건너 그 순간 그때 널 만날 수 있게 되면 아마도 기적과 같은 일이 아닐까 멈춰버린 내 시간 속에서 마침내 너를 발견한 건 천만분의 1 우리 만남을 위해 사계절을 달려 달력을 다 찢어내 수많은 인파 속 숨어있던 꽃 그게 너였기에 빛이나 더 빛이나 화려함보단 익숙한 곳 변하지 않을 수 있을까 그 순간 그때 널 만날 수 있게 되면 빛바랜 사진 속 웃고 있는 우리 둘 추억이라 말할 수 있는 그런 날이 오길 그때의 온도 그때의 하늘 노을빛마저 기억할 수 있을까', '오늘도 이렇게 어제처럼 잔을 꺼내 나 혼자서 따른 잔에 내 입술을 기대 눈물 반 소주 반 흘리고 또 비우고 얼마나 마셔야 겨우 잠들 수 있을까 나를 많이 사랑한 사람 너라서 난 좋았는데 너보다 더 나은 남자 못 만날 텐데 술이 뭐길래 난 잊으려 마신 술인데 이 술이 뭐길래 널 자꾸 더 생각나게 해 너와 내가 헤어진 후 늘어버린 두 가지는 술 그리고 그리움 오늘도 이렇게 버릇처럼 잔을 꺼내 어제보다 많은 술에 몸을 기대려 해 한숨 반 소주 반 내쉬고 또 채우고 얼마나 마셔야 겨우 취할 수 있을까 나를 많이 사랑한 사람 너라서 난 좋았는데 너보다 더 나은 여자 못 만날 텐데 술이 뭐길래 난 잊으려 마신 술인데 이 술이 뭐길래 널 자꾸 더 생각나게 해 너와 내가 헤어진 후 늘어버린 두 가지는 술 그리고 그리움 나 때문에 우린 내 잘못 때문에 헤어져 버려서 꼭 미안하다고 말하고 싶어 술이 뭐길래 이 술이 뭐길래 난 잊으려 마신 술인데 이 술이 뭐길래 널 자꾸 더 생각나게 해 너와 내가 헤어진 후 늘어버린 두 가지는 술 그리고 그리움 그리고 하나 더 한 번 더 널 사랑할 수 있길', '잘 지냈지 조금은 어색해 요즘 좋아 보여 인사 나누며 사실 궁금한 게 너무 많았는데 반가움에 멍해졌죠 생각보다 오래 된 것 같은 우리 수다스럽던 그때가 생각나 뭐가 그렇게도 할 말이 많아서 밤을 지새우곤 했죠 그리운 목소리 그리던 얼굴 참 많이도 기다렸어 다시 만나자는 너의 한마디에 울컥 눈물이 나 결국 너였단 걸 알아 기다림의 끝은 기적이 되고 기적 같은 우린 운명처럼 서로를 알아보고 그렇게 눈앞에 서있죠 우리 사랑했던 우리 다시 만나 그때 그 순간 그대로 사랑했고 사랑할 거니까 같이 듣던 노래 그때 그 거리를 이제 혼자 아닌 너와 둘이 걸어 다시 오른쪽에 나란히 발맞춰 같은 노래를 부르죠 그리운 만남을 그리던 날들 참 많이도 기다렸어 다시 너를 만나 더욱 더 소중해 같은 마음이란 걸 알아 기다림의 끝은 기적이 되고 기적 같은 우린 운명처럼 서로를 알아보고 그렇게 눈앞에 서있죠 우리 사랑했던 우리 다시 만나 그때 그 순간 그대로 사랑했고 사랑할 거니까 처음 느낌 그대로 설렘이 가득한 날 고마워 다시 돌아와줘서 그때 그 순간처럼 날 안아줘 결국 기다림의 끝은 기적이 되고 기적 같은 우린 운명처럼 서로를 알아보고 그렇게 눈앞에 서있죠 우리 사랑했던 우리 다시 만나 그때 그 순간 그대로 사랑했고 사랑할 거니까', '우리 다시 만날래 예쁘게 빛나던 모든 추억들이 너무 그리워 너의 품에 안길래 이 밤이 새도록 네게 말할 거야 너를 좋아한다고 안녕 그대야 요즘 어떻게 지내 가로수길 걷다가 생각이 나서 행복해 보이는 사람들 속에 우리 둘만 없어서 어색했었어 늘 집에 갈 땐 항상 뒤돌아보면 날 보며 웃어주던 네가 생각났어 우리 다시 만날래 예쁘게 빛나던 모든 추억들이 너무 그리워 너의 품에 안길래 이 밤이 새도록 네게 말할 거야 너를 좋아한다고 토요일마다 가던 한강공원에 이어폰 하나씩 나눠끼고서 벚꽃엔딩같이 듣고 있으면 부러울 게 없었어 너만 있으면 널 사랑할 때 내가 너무 그리워 날 보며 웃어주던 네가 보고 싶어 우리 다시 만날래 예쁘게 빛나던 모든 추억들이 너무 그리워 너의 품에 안길래 이 밤이 새도록 네게 말할 거야 너를 좋아한다고 같이 별 보러 갈래 널 다시 만나면 네 옆에 기대서 잠들고 싶어 너의 품에 안길래 이 밤이 새도록 내 곁에 있어줘 내겐 너뿐이라고', '멀리서 널 보았을 때 다른 길로 갈까 생각했는데 변한 듯한 널 보고 싶고 짧은 인사할까 하는 마음에 두근대는 가슴으로 한 걸음씩 갈 때 네 어깨 손 올리는 다른 어떤 사람 화가 난 네 얼굴은 미소로 바뀌고 두 사람은 내 옆을 지나갔지 둘이 되어버린 날 잊은 것 같은 너의 모습에 하나일 때 보다 난 외롭고 허전해 니가 가져간 나의 반쪽 때문인가 그래서 넌 둘이 될 수 있었던 거야 멀리서 널 보았을 때 다른 길로 갈까 생각했는데 변한 듯한 널 보고 싶고 짧은 인사할까 하는 마음에 두근대는 가슴으로 한 걸음씩 갈 때 네 어깨 손 올리는 다른 어떤 사람 화가 난 네 얼굴은 미소로 바뀌고 두 사람은 내 옆을 지나갔지 둘이 되어버린 날 잊은 것 같은 너의 모습에 하나일 때 보다 난 외롭고 허전해 니가 가져간 나의 반쪽 때문인가 그래서 넌 둘이 될 수 있었던 거야 지금 너에겐 변명처럼 들리겠지 널 보낸 후 항상 난 혼자였는데 둘이 되어버린 날 잊은 것 같은 너의 모습에 하나일 때 보다 난 외롭고 허전해 니가 가져간 나의 반쪽 때문인가 그래서 넌 둘이 될 수 있었던 거야 둘이 되어버린 날 잊은 것 같은 너의 모습에 하나일 때 보다 난 외롭고 허전해 니가 가져간 나의 반쪽 때문인가 그래서 넌 둘이 될 수 있었던 거야']\n",
            "['천만분의 1의 확률의 너', '술이 뭐길래', '그때 그 순간 그대로', '나의 X에게', '일과 이분의 일']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSYgYFMVABRq"
      },
      "source": [
        "# 서브워드텍스트인코더를 사용하여 가사와 제목을 모두 포함한 단어 집합(Vocabulary) 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    cut_lyric + cut_title, target_vocab_size=2**13)\n",
        "    #lyric + title, target_vocab_size=2**13)\n",
        "\n",
        "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln_by7YmGPTI",
        "outputId": "3813096b-2f1d-4f2a-edc3-bf529b747a89"
      },
      "source": [
        "print('시작 토큰 번호 :',START_TOKEN)\n",
        "print('종료 토큰 번호 :',END_TOKEN)\n",
        "print('단어 집합의 크기 :',VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시작 토큰 번호 : [8126]\n",
            "종료 토큰 번호 : [8127]\n",
            "단어 집합의 크기 : 8128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.subwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTujapcRD2Gn",
        "outputId": "e8d6ffba-a302-4bcf-d4b4-9e96786207b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7869"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnCM12LCACDB",
        "outputId": "6ec429b7-5931-4085-bb89-5f217944ffb9"
      },
      "source": [
        "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
        "print('Tokenized sample question: {}'.format(tokenizer.encode(cut_lyric[1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sample question: [335, 135, 1287, 59, 7270, 4322, 19, 2382, 515, 1037, 603, 14, 1, 6934, 3158, 541, 4341, 188, 1624, 4341, 2802, 6, 50, 134, 3869, 726, 4206, 48, 4647, 5141, 18, 475, 36, 350, 1899, 149, 4159, 7, 1976, 248, 228, 260, 32, 86, 21, 1825, 174, 1357, 948, 4098, 7902, 1837, 5870, 7, 4741, 7902, 168, 748, 1103, 1478, 2, 4098, 7902, 1837, 5870, 28, 310, 32, 3155, 17, 29, 102, 30, 7043, 7902, 1243, 2534, 267, 146, 1086, 9, 2133, 1044, 3227, 335, 135, 7234, 59, 7270, 4322, 7109, 390, 5944, 1527, 1078, 205, 29, 5022, 4341, 188, 1624, 4341, 141, 5363, 50, 3178, 6, 726, 4206, 48, 4647, 1517, 74, 18, 475, 36, 350, 1899, 149, 4159, 7, 1976, 248, 228, 260, 32, 86, 21, 1255, 174, 1357, 948, 4098, 7902, 1837, 5870, 7, 4741, 7902, 168, 748, 1103, 1478, 2, 4098, 7902, 1837, 5870, 28, 310, 32, 3155, 17, 29, 102, 30, 7043, 7902, 1243, 2534, 267, 146, 1086, 9, 2133, 1044, 3227, 19, 986, 148, 1, 1792, 7902, 986, 4607, 7902, 1266, 49, 279, 2961, 591, 2102, 152, 4098, 7902, 1837, 5870, 2, 4098, 7902, 1837, 5870, 7, 4741, 7902, 168, 748, 1103, 1478, 2, 4098, 7902, 1837, 5870, 28, 310, 32, 3155, 17, 29, 102, 30, 7043, 7902, 1243, 2534, 267, 146, 1086, 9, 2133, 1044, 3227, 1044, 249, 32, 12, 452, 32, 28, 1662, 18, 444, 415]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=[]\n",
        "for i in range(len(cut_lyric)):\n",
        "  token = tokenizer.encode(cut_lyric[i])\n",
        "  count.append(len(token))"
      ],
      "metadata": {
        "id": "CU8DbzkKEww_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2mlXmV_IuPu",
        "outputId": "8099e1dd-067f-4355-8681-2279345767cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[248, 234, 234, 180, 254, 266, 186, 199, 251, 188]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.encode(cut_lyric[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFiVvjGVIiT_",
        "outputId": "8e39cf91-a009-4cba-bf90-6f7d3487a9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "248"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWATGePyJwQW",
        "outputId": "71bfe3d0-13cc-409c-80e5-18bdafd43c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2359"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.displot(count, bins=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "YHw79YUOGcJG",
        "outputId": "99a8f177-6ecc-4a41-ac32-699727c3c08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f8f21b22a90>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXXElEQVR4nO3dcaydd33f8fenCQkVsNqGO8uzkyUsHl26qRBuk1BQ1BLFcbJSpwOStIRYWTpPWmhBbF3DkDAKRYJpK226LZXXeHWAEVICirOlCcZAUaUGYiANJAF8Mcliy4kvOIQWVJjZd3+c34WDc298Y99zfz7X75d0dJ7zfX7Pc34/naOPn/t7nuc4VYUkafH9VO8OSNKJygCWpE4MYEnqxACWpE4MYEnq5OTeHRiF9evX19133927G5I0I7MVl+QR8De/+c3eXZCkI1qSASxJ48AAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqROluTvAS+m17z2CvZPH5x13aqJFdx5+4cXuUeSxoUBfIz2Tx/krKtumHXd1Afesci9kTROnIKQpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqZGQBnOQlSe4fenwnyVuSrEiyI8nu9ry8tU+SG5NMJXkgyTlD+9rY2u9OsnFUfZakxTSyAK6qr1bVS6vqpcDLge8BHwOuB3ZW1VpgZ3sNcAmwtj02ATcBJFkBbAbOA84FNs+EtiSNs8WagrgQ+HpVPQpsALa1+jbgsra8AbilBu4FliVZBVwM7Kiqg1X1JLADWL9I/ZakkVmsAL4S+FBbXllV+9vy48DKtrwaeGxom72tNlf9JyTZlGRXkl3T09ML2XdJGomRB3CSU4BfBf7s8HVVVUAtxPtU1ZaqmqyqyYmJiYXYpSSN1GIcAV8CfKGqnmivn2hTC7TnA62+DzhtaLs1rTZXXZLG2mIE8K/z4+kHgO3AzJUMG4E7hupXt6shzgeealMV9wDrkixvJ9/WtZokjbWR/h5wkucBFwH/eqj8HuC2JNcCjwKXt/pdwKXAFIMrJq4BqKqDSd4F3Nfa3VBVs/8CuiSNkZEGcFV9F3jhYbVvMbgq4vC2BVw3x362AltH0UdJ6sU74SSpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpEwNYkjoxgCWpk5N7d2Ap2zM1xeQFFz2tvmpiBXfe/uEOPZJ0PDGAR+hQhbOuuuFp9akPvKNDbyQdb0Y6BZFkWZKPJPlKkoeTvCLJiiQ7kuxuz8tb2yS5MclUkgeSnDO0n42t/e4kG0fZZ0laLKOeA/5D4O6q+lng54GHgeuBnVW1FtjZXgNcAqxtj03ATQBJVgCbgfOAc4HNM6EtSeNsZAGc5GeAC4CbAarqB1X1bWADsK012wZc1pY3ALfUwL3AsiSrgIuBHVV1sKqeBHYA60fVb0laLKM8Aj4TmAb+R5IvJvmTJM8DVlbV/tbmcWBlW14NPDa0/d5Wm6v+E5JsSrIrya7p6ekFHookLbxRBvDJwDnATVX1MuC7/Hi6AYCqKqAW4s2qaktVTVbV5MTExELsUpJGapQBvBfYW1Wfba8/wiCQn2hTC7TnA239PuC0oe3XtNpcdUkaayML4Kp6HHgsyUta6ULgIWA7MHMlw0bgjra8Hbi6XQ1xPvBUm6q4B1iXZHk7+bau1SRprI36OuDfAj6Y5BRgD3ANg9C/Lcm1wKPA5a3tXcClwBTwvdaWqjqY5F3Afa3dDVV1cMT9lqSRG2kAV9X9wOQsqy6cpW0B182xn63A1oXtnST15W9BSFInBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InBrAkdWIAS1InIw3gJI8k+VKS+5PsarUVSXYk2d2el7d6ktyYZCrJA0nOGdrPxtZ+d5KNo+yzJC2WxTgC/uWqemlVTbbX1wM7q2otsLO9BrgEWNsem4CbYBDYwGbgPOBcYPNMaEvSOOsxBbEB2NaWtwGXDdVvqYF7gWVJVgEXAzuq6mBVPQnsANYvdqclaaGNOoAL+HiSzyfZ1Gorq2p/W34cWNmWVwOPDW27t9Xmqv+EJJuS7Eqya3p6eiHHIEkjcfKI9/+qqtqX5O8DO5J8ZXhlVVWSWog3qqotwBaAycnJBdmnJI3SSI+Aq2pfez4AfIzBHO4TbWqB9nygNd8HnDa0+ZpWm6suSWNtZAGc5HlJXjCzDKwDvgxsB2auZNgI3NGWtwNXt6shzgeealMV9wDrkixvJ9/WtZokjbVRTkGsBD6WZOZ9/mdV3Z3kPuC2JNcCjwKXt/Z3AZcCU8D3gGsAqupgkncB97V2N1TVwRH2W5IWxcgCuKr2AD8/S/1bwIWz1Au4bo59bQW2LnQfJakn74STpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqxACWpE4MYEnqZF4BnOSV86lJkuZvvkfAfzTPmiRpnk5+ppVJXgH8IjCR5K1Dq/4ecNJ83iDJScAuYF9V/UqSM4FbgRcCnwfeWFU/SHIqcAvwcuBbwBVV9Ujbx9uAa4EfAr9dVffMf4iSdHw60hHwKcDzGQT1C4Ye3wFeN8/3eDPw8NDr9wLvq6qzgCcZBCvt+clWf19rR5KzgSuBnwPWA/+thbokjbVnPAKuqr8A/iLJn1bVo89250nWAP8ceDfw1iQBXg38RmuyDXgncBOwoS0DfAT4L639BuDWqvo+8I0kU8C5wF892/5I0vHkGQN4yKlJtgBnDG9TVa8+wnZ/APx7BkfNMJh2+HZVHWqv9wKr2/Jq4LG230NJnmrtVwP3Du1zeBtJGlvzDeA/A/4Y+BMG87BHlORXgANV9fkkv3R03Zu/JJuATQCnn376qN9Oko7ZfAP4UFXd9Cz3/UrgV5NcCjyXwYm7PwSWJTm5HQWvAfa19vuA04C9SU4GfobBybiZ+ozhbX6kqrYAWwAmJyfrWfZVkhbdfC9DuzPJv0myKsmKmcczbVBVb6uqNVV1BoOTaJ+sqjcAn+LHJ/A2Ane05e3tNW39J6uqWv3KJKe2KyjWAp+b7wAl6Xg13yPgmWD8naFaAS8+ivf8XeDWJL8HfBG4udVvBt7fTrIdZBDaVNWDSW4DHgIOAddV1bymQSTpeDavAK6qM4/lTarq08Cn2/IeBlcxHN7m74DXz7H9uxlcSSFJS8a8AjjJ1bPVq+qWhe2OJJ045jsF8QtDy88FLgS+wODOtSXvNa+9gv3TB2ddt+cbj3DWIvdH0tIw3ymI3xp+nWQZg9uJTwj7pw9y1lU3zLrua5vfsMi9kbRUHO3PUX4XOKZ5YUk60c13DvhOBlc9wOBHeP4JcNuoOiVJJ4L5zgH/p6HlQ8CjVbV3BP2RpBPGvKYg2o/yfIXBbzosB34wyk5J0olgvv8jxuUM7j57PXA58Nkk8/05SknSLOY7BfF24Beq6gBAkgngEwx+NlKSdBTmexXET82Eb/OtZ7GtJGkW8z0CvjvJPcCH2usrgLtG0yVJOjEc6f+EOwtYWVW/k+RfAK9qq/4K+OCoOydJS9mRjoD/AHgbQFV9FPgoQJJ/1ta9ZqS9k6Ql7EjzuCur6kuHF1vtjJH0SJJOEEcK4GXPsO6nF7IjknSiOVIA70ryrw4vJvlN4POj6ZIknRiONAf8FuBjSd7AjwN3EjgF+LVRdkySlrpnDOCqegL4xSS/DPzTVv7fVfXJkfdMkpa4+f4e8KcY/GeakqQF4t1sktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJncz3v6V/1pI8F/gMcGp7n49U1eYkZwK3Ai9k8CPvb6yqHyQ5FbgFeDnwLeCKqnqk7ettwLXAD4Hfrqp7RtXvxbBnaorJCy6add2qiRXcefuHF7lHknoYWQAD3wdeXVV/m+Q5wF8m+XPgrcD7qurWJH/MIFhvas9PVtVZSa4E3gtckeRs4Erg54B/AHwiyT+uqh+OsO8jdajCWVfdMOu6qQ+8Y5F7I6mXkU1B1MDftpfPaY8CXg18pNW3AZe15Q3tNW39hUnS6rdW1fer6hvAFHDuqPotSYtlpHPASU5Kcj9wANgBfB34dlUdak32Aqvb8mrgMYC2/ikG0xQ/qs+yzfB7bUqyK8mu6enpUQxHkhbUSAO4qn5YVS8F1jA4av3ZEb7XlqqarKrJiYmJUb2NJC2YRbkKoqq+zeD/lHsFsCzJzNzzGmBfW94HnAbQ1v8Mg5NxP6rPso0kja2RBXCSiSTL2vJPAxcBDzMI4te1ZhuBO9ry9vaatv6TVVWtfmWSU9sVFGuBz42q35K0WEZ5FcQqYFuSkxgE/W1V9b+SPATcmuT3gC8CN7f2NwPvTzIFHGRw5QNV9WCS24CHgEPAdeN8BYQkzRhZAFfVA8DLZqnvYZarGKrq74DXz7GvdwPvXug+SlJP3gknSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ0YwJLUiQEsSZ2MLICTnJbkU0keSvJgkje3+ookO5Lsbs/LWz1JbkwyleSBJOcM7Wtja787ycZR9VmSFtMoj4APAf+2qs4GzgeuS3I2cD2ws6rWAjvba4BLgLXtsQm4CQaBDWwGzgPOBTbPhLYkjbORBXBV7a+qL7TlvwEeBlYDG4Btrdk24LK2vAG4pQbuBZYlWQVcDOyoqoNV9SSwA1g/qn5L0mJZlDngJGcALwM+C6ysqv1t1ePAyra8GnhsaLO9rTZX/fD32JRkV5Jd09PTC9p/SRqFkQdwkucDtwNvqarvDK+rqgJqId6nqrZU1WRVTU5MTCzELiVppEYawEmewyB8P1hVH23lJ9rUAu35QKvvA04b2nxNq81Vl6SxNsqrIALcDDxcVb8/tGo7MHMlw0bgjqH61e1qiPOBp9pUxT3AuiTL28m3da0mSWPt5BHu+5XAG4EvJbm/1f4D8B7gtiTXAo8Cl7d1dwGXAlPA94BrAKrqYJJ3Afe1djdU1cER9luSFsXIAriq/hLIHKsvnKV9AdfNsa+twNaF650k9eedcJLUiQEsSZ0YwJLUiQEsSZ0YwJLUySgvQ9NR2DM1xeQFFz2tvmpiBXfe/uEOPZI0KgbwceZQhbOuuuFp9akPvKNDbySNklMQktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnYwsgJNsTXIgyZeHaiuS7Eiyuz0vb/UkuTHJVJIHkpwztM3G1n53ko2j6q8kLbZRHgH/KbD+sNr1wM6qWgvsbK8BLgHWtscm4CYYBDawGTgPOBfYPBPakjTuTh7VjqvqM0nOOKy8AfiltrwN+DTwu61+S1UVcG+SZUlWtbY7quogQJIdDEL9Q6Pq9/Fqz9QUkxdcNOu6VRMruPP2Dy9yjyQdq5EF8BxWVtX+tvw4sLItrwYeG2q3t9Xmqj9Nkk0Mjp45/fTTF7DLx4dDFc666oZZ10194B2L3BtJC6HbSbh2tFsLuL8tVTVZVZMTExMLtVtJGpnFDuAn2tQC7flAq+8DThtqt6bV5qpL0thb7ADeDsxcybARuGOofnW7GuJ84Kk2VXEPsC7J8nbybV2rSdLYG9kccJIPMTiJ9qIkexlczfAe4LYk1wKPApe35ncBlwJTwPeAawCq6mCSdwH3tXY3zJyQk6RxN8qrIH59jlUXztK2gOvm2M9WYOsCdk2SjgveCSdJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnSz2z1FqBPytYGk8GcBDXvPaK9g//fSfmtjzjUc4q0N/5svfCpbGkwE8ZP/0wVmD7Gub39ChN5KWOueAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOvEytCVurps0vEFD6s8AXuLmuknDGzSk/pyCkKRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sTL0E5Q/oi71J8BfILyR9yl/pyCkKRODGBJ6sQAlqROnAPW03iCTlocBrCexhN00uIYmymIJOuTfDXJVJLre/dHko7VWBwBJzkJ+K/ARcBe4L4k26vqob49O/HMNT2x7/88yurT/+Gs2zhtIc1uLAIYOBeYqqo9AEluBTYABvAim2t64mub3zDntMXH3/kbc84pzxXczxToR7PuaLZZ6H84XvPaK9g/fXDWdf4jdWJKVfXuwxEleR2wvqp+s71+I3BeVb1pqM0mYFN7+RLgq0fxVi8CvnmM3T2eOb7xt9THuFTH982qWn94cVyOgI+oqrYAW45lH0l2VdXkAnXpuOP4xt9SH+NSH9/hxuUk3D7gtKHXa1pNksbWuATwfcDaJGcmOQW4EtjeuU+SdEzGYgqiqg4leRNwD3ASsLWqHhzBWx3TFMYYcHzjb6mPcamP7yeMxUk4SVqKxmUKQpKWHANYkjoxgFk6tzkneSTJl5Lcn2RXq61IsiPJ7va8vNWT5MY25geSnNO397NLsjXJgSRfHqo96zEl2dja706yscdYZjPH+N6ZZF/7HO9PcunQure18X01ycVD9ePyO5zktCSfSvJQkgeTvLnVl8xneEyq6oR+MDip93XgxcApwF8DZ/fu11GO5RHgRYfV/iNwfVu+HnhvW74U+HMgwPnAZ3v3f44xXQCcA3z5aMcErAD2tOflbXl577E9w/jeCfy7Wdqe3b6fpwJntu/tScfzdxhYBZzTll8AfK2NY8l8hsfy8Ah46DbnqvoBMHOb81KxAdjWlrcBlw3Vb6mBe4FlSVb16OAzqarPAIffv/tsx3QxsKOqDlbVk8AO4Gl3JfUwx/jmsgG4taq+X1XfAKYYfH+P2+9wVe2vqi+05b8BHgZWs4Q+w2NhAA++DI8Nvd7bauOogI8n+Xy7NRtgZVXtb8uPAyvb8jiP+9mOaRzH+qb2J/jWmT/PGfPxJTkDeBnwWU6Mz/CIDOCl5VVVdQ5wCXBdkguGV9bgb7kldd3hUhwTcBPwj4CXAvuB/9y3O8cuyfOB24G3VNV3htct0c9wXgzgJXSbc1Xta88HgI8x+NP0iZmphfZ8oDUf53E/2zGN1Vir6omq+mFV/T/gvzP4HGFMx5fkOQzC94NV9dFWXtKf4XwZwEvkNuckz0vygpllYB3wZQZjmTljvBG4oy1vB65uZ53PB54a+pPwePdsx3QPsC7J8vbn/LpWOy4dNhf/aww+RxiM78okpyY5E1gLfI7j+DucJMDNwMNV9ftDq5b0Zzhvvc8CHg8PBmdev8bgTPLbe/fnKMfwYgZnv/8aeHBmHMALgZ3AbuATwIpWD4Mfuf868CVgsvcY5hjXhxj8Gf5/Gcz7XXs0YwL+JYOTVlPANb3HdYTxvb/1/wEGgbRqqP3b2/i+ClxyvH+HgVcxmF54ALi/PS5dSp/hsTy8FVmSOnEKQpI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqRMDWJI6+f+Ob2RmpoO4igAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = np.array(count) "
      ],
      "metadata": {
        "id": "ucTvkU4-O0Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(np.where(count<350, 1, 0)) /len(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSDhF5G5O9dt",
        "outputId": "d58f4b0d-4d57-451a-e7c6-a3a148b8fb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8910435432482398"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(np.where(count<400, 1, 0)) /len(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9yeWC-FOYP1",
        "outputId": "6019ee43-8f15-486c-f036-3ce78541ab09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9273099162175983"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(np.where(count<450, 1, 0)) /len(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXvn0y4ePES9",
        "outputId": "f0fa5fe2-acc4-4670-f1a7-436130df92bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9517759509105927"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(np.where(count<500, 1, 0)) /len(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAFZhpnGPBRW",
        "outputId": "637de04f-09e6-460d-a6a3-4280255bc369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9699484718561933"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6616jr1ALcS",
        "outputId": "2c781d33-de6b-45eb-b587-adbdad648f00"
      },
      "source": [
        "# 서브워드텍스트인코더 토크나이저의 .encode()와 decode() 테스트해보기\n",
        "\n",
        "# 임의의 입력 문장을 sample_string에 저장\n",
        "sample_string = cut_lyric[20]\n",
        "\n",
        "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('기존 문장: {}'.format(original_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 문장 [3186, 148, 2891, 74, 77, 54, 3646, 4247, 686, 104, 481, 898, 17, 28, 1965, 10, 3821, 1715, 3646, 2090, 2577, 2854, 195, 10, 161, 1611, 2456, 4695, 266, 382, 17, 102, 1537, 37, 20, 109, 363, 128, 7155, 6, 370, 640, 4439, 1, 3342, 960, 32, 1297, 20, 1299, 1579, 20, 32, 3962, 17, 32, 266, 382, 17, 3022, 28, 4255, 1123, 2046, 807, 604, 19, 135, 167, 1594, 81, 180, 3627, 176, 50, 2499, 191, 882, 197, 3946, 28, 3718, 28, 956, 3869, 5556, 224, 1089, 8, 128, 960, 43, 3358, 46, 1899, 584, 911, 5033, 6, 72, 351, 1647, 6101, 824, 102, 236, 738, 2014, 4372, 2624, 140, 1055, 824, 515, 60, 1291, 515, 60, 126, 37, 17, 4378, 245, 20, 2176, 909, 59, 4924, 93, 118, 1429, 148, 2572, 6, 1429, 148, 659, 675, 174, 921, 2795, 64, 180, 3627, 176, 50, 2499, 191, 882, 197, 3946, 28, 3718, 28, 956, 3869, 5556, 224, 1089, 8, 128, 960, 43, 3358, 46, 1899, 584, 911, 5033, 6, 72, 351, 1647, 6101, 824, 56, 45, 2040, 59, 5160, 12, 5481, 198, 4204, 6047, 429, 200, 1194, 931, 2110, 18, 475, 2626, 93, 235, 174, 245, 379, 1573, 1228, 561, 30, 350, 1104, 3022, 235, 753, 139, 28, 268, 28, 268, 272, 2456, 4695, 63, 47, 7331, 1433, 142, 45, 1537, 39, 1981, 348, 18, 1289, 948, 348, 18, 1289, 948, 3886, 602, 410, 509, 139, 74, 18, 475, 5037, 4141, 492, 174, 6237, 139, 174, 6237, 734, 749, 5073, 389, 1293, 132, 525, 44, 2277, 245, 15, 2933, 484]\n",
            "기존 문장: 아마도 우린 특별할 것 없는 뻔한 이별이라고 주제넘게 널 달래다 재미없고 뻔한 말로 한참을 둘러대다 그동안 고마웠어 모질게 너와 헤어지던 날 한심하고 철없고 실망스런 내 모습에 어쩌면 더 빨리 날 잊을 테니까 날 더 미워하게 더 모질게 끝내 널 밀어내놓고 아무렇지 않은 척 나 이렇게 잘 살고 있어 눈을 감으면 니가 또 생각나 안 되는 줄 알면서도 널 부르고 널 외우고 잊혀질까 걱정을 하고 어쩌면 나는 나보다 너를 사랑한 걸까 몇 번이고 내게 되묻고는 했어 너와 같이 있을 때도 딴 생각을 하곤 했어 따로 먹고 따로 자던 게 익숙했던 날 오랜 친구처럼 편하다며 그래서 우린 만났고 그래서 우린 서로 아무것도 못 참았던 거야 눈을 감으면 니가 또 생각나 안 되는 줄 알면서도 널 부르고 널 외우고 잊혀질까 걱정을 하고 어쩌면 나는 나보다 너를 사랑한 걸까 몇 번이고 내게 되묻고는 했어 다시 우리 예전처럼 평범한 저녁 안부를 묻고 아무 일 없던 것처럼 돌아갈 수 있을까 바보처럼 다하지 못 했던 말을 남겨둔 채 내가 많이 미안해 끝내 하지 못한 말 널 사랑해 널 사랑해 참 고마웠어 넌 나의 세상이었어 이제 우리 헤어지면 다시는 볼 수 없을 텐데 볼 수 없을 텐데 어디서부터 어떻게 네게 말 할 수 있을까 돌려 말하는 거 못 하잖아 말 못 하잖아 그래도 기억해줄래 기억해 줘 우리만 따뜻했던 그 봄날을\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySXbL7GQAPhS"
      },
      "source": [
        "# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n",
        "# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n",
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl69HqzjATYG"
      },
      "source": [
        "# 최대 길이를 350으로 정의\n",
        "MAX_LENGTH = 350\n",
        "\n",
        "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJJc_H5oAWmC"
      },
      "source": [
        "lyric, title = tokenize_and_filter(cut_lyric, cut_title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-iBwtZqAXxC",
        "outputId": "768e749b-1a08-4e37-eb4b-cc13f73fe9f2"
      },
      "source": [
        "print('질문 데이터의 크기(shape) :', lyric.shape)\n",
        "print('답변 데이터의 크기(shape) :', title.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문 데이터의 크기(shape) : (25423, 350)\n",
            "답변 데이터의 크기(shape) : (25423, 350)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUnwWj4pAYox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc584e67-d948-4b31-c843-85a1fc3fa5f1"
      },
      "source": [
        "# 0번째 샘플을 임의로 출력\n",
        "print(lyric[0])\n",
        "print(title[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8126 2022 4233 1354 1710 2022 1908 1629  388   46 4770 7902  383   91\n",
            " 3500    8 2461 2480   14   10 5061 7902  655  962   45 2804 1604   34\n",
            "   86 5745 7902   64 3168 2812   15  322  671   28 1357   18  586 1817\n",
            " 3186 1930  121   94 1483 4766 6092    1  321  717 5203    1   46  360\n",
            " 2173   12  113  549  221  688   24 1459 1005  110  952 2234  157   15\n",
            "  975 5778  686  925   12  671 2938    2  576 5913   91   17  844  554\n",
            "   92 7183  671 3796   83  110   48  407 8106 8037 8023   17 8105 8046\n",
            " 8050 7902   22  968    2 3404   53  239  126 1312   59 7132 7902  332\n",
            "   17 3448   32 7131   17 4254 4615 2210  162  293 1219  164  582 1696\n",
            " 2805    7  528  850  228  401   45 2804 1604   34   86 5745 7902   64\n",
            " 3168 2812   15  322  671   28 1357   18  586 1817 3186 1930  121   94\n",
            " 1483 4766 6092    1  321  717 5203    1   46  360 2173   12  113  549\n",
            "  221  688   24 1459   45 3858    8  383  115 1649    8 1321  251 1999\n",
            "    8   10 7376    1 1005  233 1476  407 3540  949  692  543 4032 1545\n",
            " 6522   19   32 6522   19  294  300 1394 4424 3104  722 2776  662   18\n",
            "  475   15  322  671   28 1357   18  586 1817  823  213 4286 4466  407\n",
            " 1088  123   45  639 1076 1217 2389   18  123  254  936  107  129 2974\n",
            " 6607 7902 2974  431 2847  823 1143 3422 7902   18 4720 8127    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "[8126  549  221  688   24 7919   24 2425 8105 8035 8030   24  228 8127\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThFD6K_tAZN5",
        "outputId": "63d0f889-ffde-4b7f-d7bd-03064a8e0ec3"
      },
      "source": [
        "print('단어 집합의 크기(Vocab size): {}'.format(VOCAB_SIZE))\n",
        "print('전체 샘플의 수(Number of samples): {}'.format(len(lyric)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기(Vocab size): 8128\n",
            "전체 샘플의 수(Number of samples): 25423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FXoh56KAaBx"
      },
      "source": [
        "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
        "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': lyric,\n",
        "        'dec_inputs': title[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
        "    },\n",
        "    {\n",
        "        'outputs': title[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9vu74odAaxB",
        "outputId": "939999f2-6440-4252-8f93-6c6399257208"
      },
      "source": [
        "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
        "print(title[0]) # 기존 샘플\n",
        "print(title[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
        "print(title[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8126  549  221  688   24 7919   24 2425 8105 8035 8030   24  228 8127\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "[[8126  549  221  688   24 7919   24 2425 8105 8035 8030   24  228 8127\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "[[ 549  221  688   24 7919   24 2425 8105 8035 8030   24  228 8127    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NUM_LAYERS에서 인코딩 & 디코딩 층을 정할수 있다.**"
      ],
      "metadata": {
        "id": "IimrM-Vyh0ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 4\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT = 0.3\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dff=DFF,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aMSmxGqHzIW",
        "outputId": "5b62eabc-91a5-4d23-bf62-187b82f04071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8128, 256)\n",
            "(1, 8128, 256)\n",
            "(8128, 256)\n",
            "(1, 8128, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3qpxTy7Ainq"
      },
      "source": [
        "MAX_LENGTH = 350\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq-Ow4L0Aoqy",
        "outputId": "81f6fdec-af8b-4705-de8a-6eebbb34c2bf"
      },
      "source": [
        "EPOCHS = 1\n",
        "\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "795/795 [==============================] - 670s 793ms/step - loss: 0.1046 - accuracy: 0.0028\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f1f0b2990>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOTNLOCdArDi"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 예측 시작\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
        "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('가사: {}'.format(sentence))\n",
        "  print('예측 제목: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAHvRASLBQyz"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#벚꽃엔딩 - 버스커버스커 \n",
        "output = predict(\"\"\"\n",
        "그대여 그대여 그대여 그대여 그대여\n",
        "오늘은 우리 같이 걸어요 이 거리를\n",
        "밤에 들려오는 자장노래 어떤가요 \n",
        "몰랐던 그대와 단 둘이 손 잡고\n",
        "알 수 없는 이 떨림과 둘이 걸어요\n",
        "\n",
        "봄바람 휘날리며\n",
        "흩날리는 벚꽃 잎이\n",
        "울려 퍼질 이 거리를\n",
        "둘이 걸어요\n",
        "\n",
        "그대여 우리 이제 손 잡아요 이 거리에\n",
        "마침 들려오는 사랑 노래 어떤가요\n",
        "사랑하는 그대와 단둘이 손잡고\n",
        "알 수 없는 이 거리를 둘이 걸어요\n",
        "\n",
        "바람 불면 울렁이는 기분 탓에 나도 모르게\n",
        "바람 불면 저편에서 그대여 니 모습이 자꾸 겹쳐\n",
        "오 또 울렁이는 기분 탓에 나도 모르게\n",
        "바람 불면 저편에서 그대여 니 모습이 자꾸 겹쳐\n",
        "\n",
        "사랑하는 연인들이 많군요 알 수 없는 친구들이 많아요\n",
        "흩날리는 벚꽃 잎이 많군요 좋아요\n",
        "\n",
        "봄바람 휘날리며\n",
        "흩날리는 벚꽃 잎이\n",
        "울려 퍼질 이 거리를\n",
        "둘이 걸어요\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "tqgk2AG9qxvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#한숨 - 이하이 \n",
        "output = predict(\"\"\"\n",
        "숨을 크게 쉬어봐요\n",
        "당신의 가슴 양쪽이 저리게\n",
        "조금은 아파올 때까지\n",
        "숨을 더 뱉어봐요\n",
        "당신의 안에 남은 게 없다고\n",
        "느껴질 때까지\n",
        "숨이 벅차올라도 괜찮아요\n",
        "아무도 그댈 탓하진 않아\n",
        "가끔은 실수해도 돼\n",
        "누구든 그랬으니까\n",
        "괜찮다는 말\n",
        "말뿐인 위로지만\n",
        "누군가의 한숨\n",
        "그 무거운 숨을\n",
        "내가 어떻게\n",
        "헤아릴 수가 있을까요\n",
        "당신의 한숨\n",
        "그 깊일 이해할 순 없겠지만\n",
        "괜찮아요\n",
        "내가 안아줄게요\n",
        "누군가의 한숨\n",
        "그 무거운 숨을\n",
        "내가 어떻게\n",
        "헤아릴 수가 있을까요\n",
        "당신의 한숨\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "awTNIXrYkfJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#형 - 노라조 \n",
        "output = predict(\"\"\"\n",
        "삶이란 시련과 같은 말이야\n",
        "고개 좀 들고 어깨펴 짜샤\n",
        "형도 그랬단다 죽고 싶었지만\n",
        "견뎌 보니 괜찮더라\n",
        "맘껏 울어라 억지로 버텨라\n",
        "내일은 내일의 해가 뜰테니\n",
        "바람이 널 흔들고 소나기 널 적셔도\n",
        "살아야 갚지 않겠니\n",
        "더 울어라 젊은 인생아\n",
        "져도 괜찮아 넘어지면 어때\n",
        "살다보면 살아가다 보면\n",
        "웃고 떠들며 이날을 넌 추억할테니\n",
        "세상에 혼자라 느낄테지\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "GUgDGQLFl0BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#나는 반딧불 - 중식이 //국대위 픽\n",
        "output = predict(\"\"\"\n",
        "나는 내가 빛나는 별인 줄 알았어요\n",
        "한 번도 의심한 적 없었죠\n",
        "몰랐어요 난 내가 벌레라는 것을\n",
        "그래도 괜찮아 난 눈부시니까\n",
        "하늘에서 떨어진 별인 줄 알았어요\n",
        "소원을 들어주는 작은 별\n",
        "몰랐어요 난 내가 개똥벌레라는 것을\n",
        "그래도 괜찮아 나는 빛날 테니까\n",
        "나는 내가 빛나는 별인 줄 알았어요\n",
        "한 번도 의심한 적 없었죠\n",
        "몰랐어요 난 내가 벌레라는 것을\n",
        "그래도 괜찮아 난 눈부시니까\n",
        "한참 동안 찾았던 내 손톱\n",
        "하늘로 올라가 초승달 돼 버렸지\n",
        "주워 담을 수도 없게 너무 멀리 갔죠\n",
        "누가 저기 걸어놨어 누가 저기 걸어놨어\n",
        "우주에서 무주에서 날아온\n",
        "밤하늘의 별들이 반딧불이 돼 버렸지\n",
        "내가 널 만난 것처럼 마치 약속한 것처럼\n",
        "나는 다시 태어났지 나는 다시 태어났지\n",
        "나는 내가 빛나는 별인 줄 알았어요\n",
        "한 번도 의심한 적 없었죠\n",
        "몰랐어요 난 내가 벌레라는 것을\n",
        "그래도 괜찮아 난 눈부시니까\n",
        "하늘에서 떨어진 별인 줄 알았어요\n",
        "소원을 들어주는 작은 별\n",
        "몰랐어요 난 내가 개똥벌레란 것을\n",
        "그래도 괜찮아 나는 빛날 테니까\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "mp3QY-FAkorB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#결혼해줄래? - 이승기\n",
        "output = predict(\"\"\"\n",
        "나랑 결혼 해 줄래? 나랑 평생을 함께 살래?\n",
        "우리 둘이 알콩달콩 서로 사랑하며\n",
        "나 닮은 아이 하나\n",
        "너 닮은 아이 하나 낳고\n",
        "천년만년 아프지 말고 난 살고 싶은데\n",
        "솔직히 말해서 내가 널 더 좋아해\n",
        "남자와 여자 사이엔 그게 좋다고 하던데\n",
        "내가 더 사랑할게 내가 더 아껴줄게\n",
        "눈물이 나고 힘이 들 때면\n",
        "아플 때면 함께 아파할게\n",
        "평생을 사랑할게 평생을 지켜줄게\n",
        "너만큼 좋은 사람 만난 걸 감사해\n",
        "매일 너만 사랑하고 싶어\n",
        "나랑 결혼해 줄래\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "iJgmSL1xkH35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#사랑을 했다 - 아이콘\n",
        "output = predict(\"\"\"\n",
        "사랑을 했다 우리가 만나\n",
        "지우지 못할 추억이 됐다\n",
        "볼만한 멜로드라마, 괜찮은 결말\n",
        "그거면 됐다, 널 사랑했다\n",
        "우리가 만든 love scenario\n",
        "이젠 조명이 꺼지고\n",
        "마지막 페이지를 넘기면\n",
        "조용히 막을 내리죠\n",
        "에이, 괜찮지만은 않아 이별을 마주한다는 건\n",
        "오늘이었던 우리의 어제에 더는 내일이 없다는 건\n",
        "아프긴 해도 더 끌었음 상처가 덧나니까\n",
        "널 사랑했고 사랑 받았으니 난 이걸로 됐어\n",
        "나 살아가면서 가끔씩 떠오를 기억\n",
        "그 안에 네가 있다면 그거면 충분해\n",
        "사랑을 했다 우리가 만나\n",
        "지우지 못할 추억이 됐다\n",
        "볼만한 멜로드라마, 괜찮은 결말\n",
        "그거면 됐다, 널 사랑했다\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "cfMPhqR5jj6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUl6DCxFUvm2"
      },
      "source": [
        "#광대 - 리쌍\n",
        "output = predict(\"\"\"\n",
        "오- 내가 웃고 있나요? \n",
        "모두 거짓이겠죠?\n",
        "날 보는 이들의 눈빛 속에는 \n",
        "슬픔이 젖어있는데.\n",
        "내 이름은 광대, 내 직업은 수많은 관객,\n",
        "그 앞에 웃음을 파는 일\n",
        "슬퍼도 웃으며 내 모습을 감추는 게 철칙.\n",
        "오- 이런 내 처질, 손가락질 하며 날 모욕해도\n",
        "더 크게 웃고 난 땀으로 목욕하고\n",
        "음악이 꺼지고 막이 내리고 밤이 오면\n",
        "별빛에 몸을 씻고 눈부시게\n",
        "광낸 구두를 신고 달에게 청혼하듯 손\n",
        "을 내밀어 얼음 위를 미끄러지듯\n",
        "앞으로 달려  아무도 모르게\n",
        "조용히 흐르는 이 시간에\n",
        "외롭게 홀로 핀 꽃 한 송이에 난 반해\n",
        "사랑을 나누려 나는 간다네\n",
        "\"\"\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#청춘 - 김필\n",
        "output = predict(\"\"\"\n",
        "언젠간 가겠지 푸르른 이 청춘\n",
        "지고 또 피는 꽃잎처럼\n",
        "달밝은 밤이면 창가에 흐르는\n",
        "내 젊은 연가가 구슬퍼\n",
        "가고없는 날들을 잡으려 잡으려\n",
        "빈손짓에 슬퍼지면\n",
        "차라리 보내야지 돌아서야지\n",
        "그렇게 세월은 가는거야\n",
        "나를 두고 간님은 용서하겠지만\n",
        "날 버리고 가는 세월이야\n",
        "정둘곳없어라 허전한 마음은\n",
        "정답던 옛동산 찾는가\n",
        "언젠간 가겠지 푸르른 이 청춘\n",
        "지고 또 피는 꽃잎처럼\n",
        "달밝은 밤이면 창가에 흐르는\n",
        "내 젊은 연가가 구슬퍼\n",
        "가고없는 날들을 잡으려 잡으려\n",
        "빈손짓에 슬퍼지면\n",
        "차라리 보내야지 돌아서야지\n",
        "그렇게 세월은 가는거야\n",
        "언젠간 가겠지 푸르른 이 청춘\n",
        "지고 또 피는 꽃잎처럼\n",
        "달밝은 밤이면 창가에 흐르는\n",
        "내 젊은 연가가 구슬퍼\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "Fn1Q4mJt0EJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#다시만난세계 - 소녀시대\n",
        "output = predict(\"\"\"\n",
        "전해주고 싶어 슬픈 시간이 다 흩어진 후에야 들리지만\n",
        "눈을 감고 느껴봐 움직이는 마음 너를 향한 내 눈빛을\n",
        "특별한 기적을 기다리지마 눈 앞에선 우리의 거친 길은\n",
        "알 수 없는 미래와 벽 바꾸지 않아 포기할 수 없어\n",
        "변치 않을 사랑으로 지켜줘 상처 입은 내 맘까지\n",
        "시선 속에서 말은 필요 없어 멈춰져 버린 이 시간\n",
        "사랑해 널 이 느낌 이대로 그려왔던 헤매임의 끝\n",
        "이 세상 속에서 반복되는 슬픔 이젠 안녕\n",
        "수많은 알 수 없는 길 속에 희미한 빛을 난 쫓아가\n",
        "언제까지라도 함께 하는거야 다시 만난 나의 세계\n",
        "특별한 기적을 기다리지마 눈 앞에선 우리의 거친 길은\n",
        "알 수 없는 미래와 벽 바꾸지 않아 포기할 수 없어\n",
        "변치 않을 사랑으로 지켜줘 상처 입은 내 맘까지\n",
        "시선 속에서 말은 필요 없어 멈춰져 버린 이 시간\n",
        "사랑해 널 이 느낌 이대로 그려왔던 헤매임의 끝\n",
        "이 세상 속에서 반복되는 슬픔 이젠 안녕\n",
        "수많은 알 수 없는 길 속에 희미한 빛을 난 쫓아가\n",
        "언제까지라도 함께 하는거야 다시 만난 우리의\n",
        "이렇게 까만 밤 홀로 느끼는 그대의 부드러운 숨결이\n",
        "이 순간 따스하게 감겨오는 모든 나의 떨림 전할래\n",
        "사랑해 널 이 느낌 이대로 그려왔던 헤매임의 끝\n",
        "이 세상 속에서 반복되는 슬픔 이젠 안녕\n",
        "널 생각만 해도 난 강해져 울지 않게 나를 도와줘\n",
        "이 순간의 느낌 함께 하는거야 다시 만난 우리의\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "NP9j4EjJtVCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#제목 - 사람\n",
        "output = predict(\"\"\"\n",
        "\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "xYn6kC-rzS6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#꽃길 - 빅뱅\n",
        "output = predict(\"\"\"\n",
        "그땐 참 좋았는데 말이야\n",
        "너와 함께할 수만 있다면\n",
        "때론 외롭고 슬퍼도 말이야\n",
        "너와 같이 할 수만 있다면\n",
        "Sing it na na na\n",
        "노래해 나나나\n",
        "우리 이게 마지막이 아니야\n",
        "부디 또 만나요 꽃이 피면\n",
        "때론 꽤 별난 일이 많아\n",
        "넌 나 같이 못난 놈을 만나\n",
        "다시 누군갈 사랑할 수 있을까?\n",
        "너 아니라면 그럴 일은 없을 것 같아\n",
        "나 의식 없이 발길 흐름대로 가던 길\n",
        "날 화려히 비춰주던 네 빛 한줄기\n",
        "그 전율이 느껴지는 예쁜 꽃 길\n",
        "그곳에 너로 인해 설수 있던 Roly poly toy\n",
        "떠나려거든 보내 드리오리다\n",
        "님이 가시는 길에 꽃을 뿌리오리다\n",
        "그리워지면 돌아와 줘요\n",
        "그때 또 다시 날 사랑해줘요\n",
        "이 꽃 길 따라 잠시 쉬어가다가\n",
        "그 자리 그곳에서 날 기다려요\n",
        "그땐 참 좋았는데 말이야\n",
        "너와 함께할 수만 있다면\n",
        "때론 외롭고 슬퍼도 말이야\n",
        "너와 같이 할 수만 있다면\n",
        "많이 울기도 했지만 웃은 일도 많아\n",
        "내 머릿속 안에는 추억이 너무 많아\n",
        "이 또한 지나갈 테니까\n",
        "이 다음에 만나요 꽃이 피면\n",
        "1년 365 이 세상 하나뿐인\n",
        "넌 내 음악의 Motive 날 일깨워주는 은인\n",
        "네 커다란 꽃밭에 기대어 막 떠오르던 가사말\n",
        "아직도 참 생생해 빠담빠담\n",
        "너란 만개 한 꽃의 색은 100000 개\n",
        "무한대 거대한 울림 Vivaldi의 사계\n",
        "아직도 그댄 내 맘에 담을 수 없는 그림\n",
        "내 눈을 의심하지 You are my Magical Queen\n",
        "떠나려거든 보내 드리오리다\n",
        "님이 가시는 길에 꽃을 뿌리오리다\n",
        "그리워지면 돌아와 줘요\n",
        "그때 또 다시 날 사랑해줘요\n",
        "이 꽃 길 따라 잠시 쉬어가다가\n",
        "그 자리 그곳에서 날 기다려요\n",
        "꽃 잎 따다 입을 맞추죠 얼굴은 빨개지고\n",
        "꽃 길을 깔아 준비를 하죠 그대가 오시는 길\n",
        "그리워지면 돌아와 줘요\n",
        "그때 또 다시 날 사랑해줘요\n",
        "이 꽃 길 따라 잠시 쉬어가다가\n",
        "그 자리 그곳에서 날 기다려요\n",
        "꽃 잎 따다 입을 맞추죠 얼굴은 빨개지고\n",
        "꽃 길을 깔아 준비를 하죠\n",
        "그 자리 그곳에서 날 기다려요\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "FRMd8HVEtzRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#꽃길 - 김세정\n",
        "output = predict(\"\"\"\n",
        "그땐 참 좋았는데 말이야\n",
        "너와 함께할 수만 있다면\n",
        "때론 외롭고 슬퍼도 말이야\n",
        "너와 같이 할 수만 있다면\n",
        "Sing it na na na\n",
        "노래해 나나나\n",
        "우리 이게 마지막이 아니야\n",
        "부디 또 만나요 꽃이 피면\n",
        "때론 꽤 별난 일이 많아\n",
        "넌 나 같이 못난 놈을 만나\n",
        "다시 누군갈 사랑할 수 있을까?\n",
        "너 아니라면 그럴 일은 없을 것 같아\n",
        "나 의식 없이 발길 흐름대로 가던 길\n",
        "날 화려히 비춰주던 네 빛 한줄기\n",
        "그 전율이 느껴지는 예쁜 꽃 길\n",
        "그곳에 너로 인해 설수 있던 Roly poly toy\n",
        "떠나려거든 보내 드리오리다\n",
        "님이 가시는 길에 꽃을 뿌리오리다\n",
        "그리워지면 돌아와 줘요\n",
        "그때 또 다시 날 사랑해줘요\n",
        "이 꽃 길 따라 잠시 쉬어가다가\n",
        "그 자리 그곳에서 날 기다려요\n",
        "그땐 참 좋았는데 말이야\n",
        "너와 함께할 수만 있다면\n",
        "때론 외롭고 슬퍼도 말이야\n",
        "너와 같이 할 수만 있다면\n",
        "많이 울기도 했지만 웃은 일도 많아\n",
        "내 머릿속 안에는 추억이 너무 많아\n",
        "이 또한 지나갈 테니까\n",
        "이 다음에 만나요 꽃이 피면\n",
        "1년 365 이 세상 하나뿐인\n",
        "넌 내 음악의 Motive 날 일깨워주는 은인\n",
        "네 커다란 꽃밭에 기대어 막 떠오르던 가사말\n",
        "아직도 참 생생해 빠담빠담\n",
        "너란 만개 한 꽃의 색은 100000 개\n",
        "무한대 거대한 울림 Vivaldi의 사계\n",
        "아직도 그댄 내 맘에 담을 수 없는 그림\n",
        "내 눈을 의심하지 You are my Magical Queen\n",
        "떠나려거든 보내 드리오리다\n",
        "님이 가시는 길에 꽃을 뿌리오리다\n",
        "그리워지면 돌아와 줘요\n",
        "그때 또 다시 날 사랑해줘요\n",
        "이 꽃 길 따라 잠시 쉬어가다가\n",
        "그 자리 그곳에서 날 기다려요\n",
        "꽃 잎 따다 입을 맞추죠 얼굴은 빨개지고\n",
        "꽃 길을 깔아 준비를 하죠 그대가 오시는 길\n",
        "그리워지면 돌아와 줘요\n",
        "그때 또 다시 날 사랑해줘요\n",
        "이 꽃 길 따라 잠시 쉬어가다가\n",
        "그 자리 그곳에서 날 기다려요\n",
        "꽃 잎 따다 입을 맞추죠 얼굴은 빨개지고\n",
        "꽃 길을 깔아 준비를 하죠\n",
        "그 자리 그곳에서 날 기다려요\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "MuYPR_8Uubj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#슈퍼맨 - 노라조\n",
        "output = predict(\"\"\"\n",
        "아들아 지구를 부탁하노라\n",
        "아버지 걱정은 하지마세요\n",
        "\n",
        "바지 위에 팬티입고 오늘도 난 길을 나서네\n",
        "\n",
        "아들아 망토는 하고 가야지\n",
        "아뿔싸 어쩐지 허전하더라\n",
        "\n",
        "파란 타이즈에 빨간 팬티는 내 charming point\n",
        "오늘도 달리고 달리고 달리고 달리고\n",
        "살리고 살리고 살리고 살리고\n",
        "돌아라 지구 열 두바퀴\n",
        "\n",
        "올빽머리 근육빵빵 난 슈퍼맨\n",
        "지구인의 친구 난 슈퍼맨\n",
        "\n",
        "멋지구나 잘생겼다\n",
        "대인배의 카리스마 사이즈가 장난아니지\n",
        "\n",
        "어쨌거나 근육빵빵 난 슈퍼맨\n",
        "지구인의 친구 난 슈퍼맨\n",
        "유사품에 주의해요\n",
        "오각형에 S자야\n",
        "위아래로 스판100%\n",
        "\n",
        "아들아 아침은 먹고가야지\n",
        "아버지 빈 속이 날기 편해요\n",
        "\n",
        "서울대전대구부산 찍고나서\n",
        "독도 한바퀴\n",
        "\n",
        "오늘도 달리고 달리고 달리고 달리고\n",
        "살리고 살리고 살리고 살리고\n",
        "돌아라 지구 열두바퀴\n",
        "\n",
        "올빽머리 근육빵빵 난 슈퍼맨\n",
        "지구인의 친구 난 슈퍼맨\n",
        "멋지구나 잘생겼다\n",
        "대인배의 카리스마 사이즈가 장난아니지\n",
        "\n",
        "어쨌거나 근육빵빵 난 슈퍼맨\n",
        "지구인의 친구 난 슈퍼맨\n",
        "유사품에 주의해요\n",
        "오각형에 S자야\n",
        "위아래로 스판100%\n",
        "\n",
        "오늘도 달리고 달리고 달리고 달리고\n",
        "살리고 살리고 살리고 살리고\n",
        "돌아라 지구 열두바퀴\n",
        "\n",
        "올빽머리 근육빵빵 난 슈퍼맨\n",
        "지구인의 친구 난 슈퍼맨\n",
        "\n",
        "위기때면 나타난다 밤하늘의 박쥐모양\n",
        "아참 그건 배트맨이지\n",
        "\n",
        "어쨌거나 근육빵빵 난 슈퍼맨\n",
        "지구인의 친구 난 슈퍼맨\n",
        "\n",
        "위험할땐 불러줘요 언제든지 달려갈게\n",
        "나는야 정의의 슈퍼맨\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "pKbBYCuXu5QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#소주 한 잔 - 임창정\n",
        "output = predict(\"\"\"\n",
        "술이 한 잔 생각나는 밤 같이 있는 것 같아요\n",
        "그 좋았던 시절들 이젠 모두 한숨만 되네요\n",
        "\n",
        "떠나는 그대 얼굴이 혹시 울지나 않을까\n",
        "나 먼저 돌아섰죠 그때부터 그리워요\n",
        "\n",
        "사람이 변하는 걸요 다시 전보다 그댈 원해요\n",
        "이렇게 취할 때면 꺼져버린 전화를 붙잡고\n",
        "\n",
        "여보세요 나야 거기 잘 지내니 여보세요 왜 말 안하니\n",
        "울고 있니 내가 오랜만이라서 사랑하는 사람이라서\n",
        "\n",
        "그대 소중한 마음 밀쳐낸 이기적인 그때의 나에게\n",
        "그대를 다시 불러오라고 미친 듯이 외쳤어\n",
        "\n",
        "떠나는 그대 얼굴이 마치 처음과 같아서\n",
        "나 눈물이 났어요 그때부터 그리워요\n",
        "\n",
        "사람이 변하는 걸요 다시 전보다 그댈 원해요\n",
        "이렇게 취할때면 바뀌어버린 전화번호 누르고\n",
        "\n",
        "여보세요 나야 거기 잘 지내니 오랜만이야 내 사랑아\n",
        "그대를 다시 불러오라고 미친 듯이 울었어 우-\n",
        "\n",
        "여보세요 나야 정말 미안해 이기적인 그때의 나에게\n",
        "그대를 다시 불러오라고 미친 듯이 외쳤어\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "_ClDLPmtvEZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hello - 허각\n",
        "output = predict(\"\"\"\n",
        "우리 헤어지면 안되잖아\n",
        "우리 이별하긴 이르잖아\n",
        "이렇게 날 떠나가면 안돼요\n",
        "내가 하지 못한 말들이 아직 너무 많은데\n",
        "이대로 날 떠나가지 마세요\n",
        "\n",
        "그대이기 때문에 난\n",
        "정말 그대였기 때문에 난\n",
        "이대로는, 이대로는 난 안돼요\n",
        "내가 살아가는 이유는 오직 그대 뿐이죠\n",
        "제발 나를 떠나가지 말아요\n",
        "\n",
        "그대는 내 사랑 그리운 내 사랑 날 사랑했던 사람\n",
        "이제는 만질 수 없지만\n",
        "내가 그리운 만큼 그대도 그리운가요\n",
        "내가 미칠 듯이 사랑했던 그 사람 hello\n",
        "사랑했기 때문에 난\n",
        "정말 사랑했기 때문에 난\n",
        "죽을 만큼, 죽을 만큼 힘드네요\n",
        "죽지 못해 살아가고 있는 내가 보이나요\n",
        "제발 내게 다시 돌아와줘요\n",
        "\n",
        "그대는 내사랑 그리운 내사랑 날 사랑했던 사람\n",
        "이제는 만질 수 없지만\n",
        "내가 그리운 만큼 그대도 그리운가요\n",
        "내가 미칠 듯이 사랑했던 그 사람\n",
        "\n",
        "겨우 이대로 끝날 거라면\n",
        "정말 마지막이라면\n",
        "지금 돌아가 그때로 서로 몰랐던 그때로\n",
        "너무 늦어버리면 너무 늦어버리면\n",
        "내가 살아가는 게 너무 힘이 들어 날 버릴까 봐\n",
        "\n",
        "정말 이대로 끝날 거라면\n",
        "이게 마지막이라면\n",
        "지금 돌아가 그때로 서로 몰랐던 그때로\n",
        "너무 늦어버리면 너무 늦어버리면\n",
        "내가 살아가는 게 너무 힘이 들어 날 버릴까 봐\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "8tied9bGwnGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hello - 허각\n",
        "output = predict(\"\"\"\n",
        "우리 사랑했었자나~~\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "clxweYf2wr5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMdVXTIp4s-T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}